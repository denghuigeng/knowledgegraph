#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸ºèŠ‚ç‚¹ç”Ÿæˆ embeddingï¼Œä½¿ç”¨ bge-multilingual-gemma2 æ¨¡å‹
å‚è€ƒ: https://github.com/FlagOpen/FlagEmbedding/blob/master/README_zh.md
"""

import os
import csv
import json
import numpy as np
from typing import List, Dict
from tqdm import tqdm
import torch

os.environ["CUDA_VISIBLE_DEVICES"] = "0,2,5"
os.environ["BGE_MODEL_PATH"] = "/data/gdh/knowledgegraph/models/bge-multilingual-gemma2"
def load_model():
    """åŠ è½½ bge-multilingual-gemma2 æ¨¡å‹

    ä¼˜å…ˆä»æœ¬åœ°è·¯å¾„åŠ è½½ï¼Œä»¥é¿å…æ¯æ¬¡éƒ½ä» HuggingFace ä¸‹è½½ï¼š
    - å¦‚æœè®¾ç½®äº†ç¯å¢ƒå˜é‡ BGE_MODEL_PATH ä¸”ç›®å½•å­˜åœ¨ï¼Œåˆ™ä»è¯¥ç›®å½•åŠ è½½
    - å¦åˆ™ä» HuggingFace Hub åŠ è½½: 'BAAI/bge-multilingual-gemma2'
    """
    try:
        from FlagEmbedding import FlagModel

        # ä¼˜å…ˆä½¿ç”¨æœ¬åœ°æ¨¡å‹ç›®å½•ï¼ˆä¾‹å¦‚: /data/models/bge-multilingual-gemma2ï¼‰
        local_model_path = os.getenv("BGE_MODEL_PATH", "").strip()
        if local_model_path and os.path.isdir(local_model_path):
            print(f"ğŸ“¦ ä»æœ¬åœ°ç›®å½•åŠ è½½ bge-multilingual-gemma2 æ¨¡å‹: {local_model_path}")
            model_name_or_path = local_model_path
        else:
            # é€€å›åˆ°åœ¨çº¿åŠ è½½
            model_name_or_path = "BAAI/bge-multilingual-gemma2"
            print("ğŸ“¦ ä» HuggingFace Hub åŠ è½½ bge-multilingual-gemma2 æ¨¡å‹...")
            print("   å¦‚éœ€æœ¬åœ°åŠ è½½ï¼Œå¯å…ˆä¸‹è½½æ¨¡å‹å¹¶è®¾ç½®ç¯å¢ƒå˜é‡ BGE_MODEL_PATH=æœ¬åœ°æ¨¡å‹ç›®å½•")

        model = FlagModel(model_name_or_path, use_fp16=True)
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        return model
    except ImportError:
        print("âŒ é”™è¯¯: è¯·å…ˆå®‰è£… FlagEmbedding")
        print("   å®‰è£…å‘½ä»¤: pip install FlagEmbedding")
        raise
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        raise


def generate_text_for_embedding(node: Dict, node_type: str) -> str:
    """æ ¹æ®èŠ‚ç‚¹ç±»å‹ç”Ÿæˆç”¨äº embedding çš„æ–‡æœ¬"""
    if node_type == 'Paper':
        # è®ºæ–‡èŠ‚ç‚¹ï¼šä½¿ç”¨æ ‡é¢˜å’Œç±»åˆ«
        title = node.get('title', '')
        category = node.get('category', '')
        return f"{title} {category}".strip()
    
    elif node_type == 'Task':
        return node.get('name', '')
    
    elif node_type == 'ImagingModality':
        return node.get('name', '')
    
    elif node_type == 'AnatomicalStructure':
        return node.get('name', '')
    
    elif node_type == 'Method':
        name = node.get('name', '')
        method_type = node.get('method_type', '')
        return f"{name} {method_type}".strip()
    
    elif node_type == 'Dataset':
        return node.get('name', '')
    
    elif node_type == 'Metric':
        return node.get('name', '')
    
    elif node_type == 'Innovation':
        description = node.get('description', '')
        innovation_type = node.get('innovation_type', '')
        return f"{description} {innovation_type}".strip()
    
    return ""


def l2_normalize(vectors: np.ndarray) -> np.ndarray:
    """å¯¹å‘é‡è¿›è¡Œ L2 å½’ä¸€åŒ–"""
    norms = np.linalg.norm(vectors, axis=1, keepdims=True)
    norms = np.clip(norms, 1e-12, None)
    return vectors / norms


def update_csv_with_embeddings(csv_dir: str, model, batch_size: int = 16):
    """ä¸ºæ‰€æœ‰èŠ‚ç‚¹ CSV æ–‡ä»¶æ·»åŠ  embedding"""
    node_types = ['Paper', 'Task', 'ImagingModality', 'AnatomicalStructure', 
                  'Method', 'Dataset', 'Metric', 'Innovation']
    
    for node_type in node_types:
        csv_file = os.path.join(csv_dir, f'nodes_{node_type}.csv')
        
        if not os.path.exists(csv_file):
            print(f"âš  è·³è¿‡ä¸å­˜åœ¨çš„æ–‡ä»¶: {csv_file}")
            continue
        
        print(f"\nğŸ”„ å¤„ç† {node_type} èŠ‚ç‚¹...")
        
        # è¯»å– CSV
        rows = []
        texts = []
        with open(csv_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                rows.append(row)
                text = generate_text_for_embedding(row, node_type)
                texts.append(text if text else " ")  # ç©ºæ–‡æœ¬ç”¨ç©ºæ ¼ä»£æ›¿
        
        if not rows:
            print(f"   âš  {node_type} èŠ‚ç‚¹ä¸ºç©ºï¼Œè·³è¿‡")
            continue
        
        # æ‰¹é‡ç”Ÿæˆ embedding
        print(f"   ğŸ“Š ç”Ÿæˆ {len(texts)} ä¸ªèŠ‚ç‚¹çš„ embedding...")
        embeddings: List[np.ndarray] = []
        
        for i in tqdm(range(0, len(texts), batch_size), desc=f"   Processing {node_type}"):
            batch_texts = texts[i:i+batch_size]
            # ä¸å†å‘ FlagEmbedding ä¼ é€’ normalize_embeddingsï¼Œé¿å…ä¸å†…éƒ¨å®ç°å†²çª
            batch_embeddings = model.encode(batch_texts)
            batch_embeddings = np.asarray(batch_embeddings, dtype="float32")
            batch_embeddings = l2_normalize(batch_embeddings)
            embeddings.extend(batch_embeddings)
        
        # æ›´æ–° CSV æ–‡ä»¶
        print(f"   ğŸ’¾ æ›´æ–° CSV æ–‡ä»¶...")
        with open(csv_file, 'w', newline='', encoding='utf-8') as f:
            fieldnames = list(rows[0].keys())
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            
            for row, embedding in zip(rows, embeddings):
                # å°† embedding è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼ˆé€—å·åˆ†éš”ï¼‰
                row['embedding'] = ','.join(map(str, embedding.tolist()))
                writer.writerow(row)
        
        print(f"   âœ… {node_type} èŠ‚ç‚¹å¤„ç†å®Œæˆ ({len(rows)} ä¸ªèŠ‚ç‚¹)")


def main():
    """ä¸»å‡½æ•°"""
    script_dir = os.path.dirname(os.path.abspath(__file__))
    csv_dir = os.path.join(script_dir, 'csv')
    
    if not os.path.exists(csv_dir):
        print(f"âŒ CSV ç›®å½•ä¸å­˜åœ¨: {csv_dir}")
        print("   è¯·å…ˆè¿è¡Œ json_to_csv.py ç”Ÿæˆ CSV æ–‡ä»¶")
        return
    
    # åŠ è½½æ¨¡å‹
    model = load_model()
    
    # ç”Ÿæˆ embedding
    update_csv_with_embeddings(csv_dir, model, batch_size=32)
    
    print("\nâœ… Embedding ç”Ÿæˆå®Œæˆ!")


if __name__ == '__main__':
    main()

