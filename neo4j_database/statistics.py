#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å›¾è°±ç»Ÿè®¡å’ŒéªŒè¯è„šæœ¬
- èŠ‚ç‚¹ç»Ÿè®¡
- å…³ç³»ç»Ÿè®¡
- ç»“æ„éªŒè¯
"""

import os
import csv
import json
from collections import Counter, defaultdict
from typing import Dict, List


def count_nodes(csv_dir: str) -> Dict[str, int]:
    """ç»Ÿè®¡å„ç±»å‹èŠ‚ç‚¹æ•°é‡"""
    print("=" * 60)
    print("ğŸ“Š èŠ‚ç‚¹ç»Ÿè®¡")
    print("=" * 60)
    
    node_types = ['Paper', 'Task', 'ImagingModality', 'AnatomicalStructure',
                 'Method', 'Dataset', 'Metric', 'Innovation']
    
    node_counts = {}
    total = 0
    
    for node_type in node_types:
        csv_file = os.path.join(csv_dir, f'nodes_{node_type}.csv')
        
        if not os.path.exists(csv_file):
            node_counts[node_type] = 0
            continue
        
        count = 0
        with open(csv_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            count = sum(1 for _ in reader)
        
        node_counts[node_type] = count
        total += count
        print(f"   {node_type:20s}: {count:6d} ä¸ªèŠ‚ç‚¹")
    
    print(f"   {'æ€»è®¡':20s}: {total:6d} ä¸ªèŠ‚ç‚¹")
    print()
    
    return node_counts


def count_relations(csv_dir: str) -> Dict:
    """ç»Ÿè®¡å…³ç³»"""
    print("=" * 60)
    print("ğŸ“Š å…³ç³»ç»Ÿè®¡")
    print("=" * 60)
    
    relations_file = os.path.join(csv_dir, 'relations.csv')
    
    if not os.path.exists(relations_file):
        print("âš  å…³ç³»æ–‡ä»¶ä¸å­˜åœ¨")
        return {}
    
    relation_types = Counter()
    total = 0
    
    with open(relations_file, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            rel_type = row.get('type', 'UNKNOWN')
            relation_types[rel_type] += 1
            total += 1
    
    print(f"   æ€»å…³ç³»æ•°: {total}")
    print(f"\n   å…³ç³»ç±»å‹åˆ†å¸ƒ:")
    for rel_type, count in relation_types.most_common():
        percentage = count / total * 100 if total > 0 else 0
        print(f"      {rel_type:30s}: {count:6d} æ¡ ({percentage:5.1f}%)")
    print()
    
    return {
        'total': total,
        'by_type': dict(relation_types)
    }


def analyze_paper_statistics(csv_dir: str) -> Dict:
    """åˆ†æè®ºæ–‡ç»Ÿè®¡ä¿¡æ¯"""
    print("=" * 60)
    print("ğŸ“Š è®ºæ–‡ç»Ÿè®¡")
    print("=" * 60)
    
    csv_file = os.path.join(csv_dir, 'nodes_Paper.csv')
    
    if not os.path.exists(csv_file):
        print("âš  è®ºæ–‡æ–‡ä»¶ä¸å­˜åœ¨")
        return {}
    
    papers = []
    years = []
    categories = Counter()
    
    with open(csv_file, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            papers.append(row)
            year = row.get('year', '')
            if year and year.isdigit():
                years.append(int(year))
            category = row.get('category', '')
            if category:
                categories[category] += 1
    
    stats = {
        'total_papers': len(papers),
        'year_range': {
            'min': min(years) if years else None,
            'max': max(years) if years else None
        },
        'year_distribution': Counter(years),
        'top_categories': dict(categories.most_common(10))
    }
    
    print(f"   æ€»è®ºæ–‡æ•°: {stats['total_papers']}")
    if stats['year_range']['min']:
        print(f"   å¹´ä»½èŒƒå›´: {stats['year_range']['min']} - {stats['year_range']['max']}")
    
    print(f"\n   çƒ­é—¨ç±»åˆ« (Top 10):")
    for category, count in list(categories.most_common(10)):
        print(f"      {category:40s}: {count:4d} ç¯‡")
    print()
    
    return stats


def analyze_node_connectivity(csv_dir: str) -> Dict:
    """åˆ†æèŠ‚ç‚¹è¿æ¥åº¦"""
    print("=" * 60)
    print("ğŸ“Š èŠ‚ç‚¹è¿æ¥åº¦åˆ†æ")
    print("=" * 60)
    
    relations_file = os.path.join(csv_dir, 'relations.csv')
    
    if not os.path.exists(relations_file):
        print("âš  å…³ç³»æ–‡ä»¶ä¸å­˜åœ¨")
        return {}
    
    # ç»Ÿè®¡æ¯ä¸ªèŠ‚ç‚¹çš„è¿æ¥æ•°
    node_degrees = defaultdict(int)
    
    with open(relations_file, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            from_id = row.get('from_id', '')
            to_id = row.get('to_id', '')
            node_degrees[from_id] += 1
            node_degrees[to_id] += 1
    
    if not node_degrees:
        print("âš  æ²¡æœ‰å…³ç³»æ•°æ®")
        return {}
    
    degrees = list(node_degrees.values())
    stats = {
        'total_nodes_with_relations': len(node_degrees),
        'max_degree': max(degrees),
        'min_degree': min(degrees),
        'avg_degree': sum(degrees) / len(degrees) if degrees else 0,
        'median_degree': sorted(degrees)[len(degrees) // 2] if degrees else 0
    }
    
    print(f"   æœ‰è¿æ¥çš„èŠ‚ç‚¹æ•°: {stats['total_nodes_with_relations']}")
    print(f"   æœ€å¤§è¿æ¥åº¦: {stats['max_degree']}")
    print(f"   æœ€å°è¿æ¥åº¦: {stats['min_degree']}")
    print(f"   å¹³å‡è¿æ¥åº¦: {stats['avg_degree']:.2f}")
    print(f"   ä¸­ä½æ•°è¿æ¥åº¦: {stats['median_degree']}")
    print()
    
    # æ‰¾å‡ºè¿æ¥åº¦æœ€é«˜çš„èŠ‚ç‚¹
    top_nodes = sorted(node_degrees.items(), key=lambda x: x[1], reverse=True)[:10]
    print(f"   è¿æ¥åº¦æœ€é«˜çš„èŠ‚ç‚¹ (Top 10):")
    for node_id, degree in top_nodes:
        print(f"      {node_id[:20]:20s}: {degree:4d} æ¡è¿æ¥")
    print()
    
    return stats


def validate_structure(csv_dir: str) -> Dict:
    """éªŒè¯å›¾è°±ç»“æ„"""
    print("=" * 60)
    print("ğŸ” ç»“æ„éªŒè¯")
    print("=" * 60)
    
    issues = []
    
    # æ£€æŸ¥å¿…éœ€çš„æ–‡ä»¶
    required_files = [
        'nodes_Paper.csv',
        'relations.csv'
    ]
    
    for filename in required_files:
        filepath = os.path.join(csv_dir, filename)
        if not os.path.exists(filepath):
            issues.append(f"ç¼ºå¤±å¿…éœ€æ–‡ä»¶: {filename}")
    
    # æ£€æŸ¥èŠ‚ç‚¹IDå”¯ä¸€æ€§
    all_node_ids = set()
    node_types = ['Paper', 'Task', 'ImagingModality', 'AnatomicalStructure',
                 'Method', 'Dataset', 'Metric', 'Innovation']
    
    for node_type in node_types:
        csv_file = os.path.join(csv_dir, f'nodes_{node_type}.csv')
        if os.path.exists(csv_file):
            with open(csv_file, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    node_id = row.get('id', '')
                    if node_id:
                        if node_id in all_node_ids:
                            issues.append(f"é‡å¤çš„èŠ‚ç‚¹ID: {node_id} (ç±»å‹: {node_type})")
                        all_node_ids.add(node_id)
    
    # æ£€æŸ¥å…³ç³»ä¸­çš„èŠ‚ç‚¹IDæ˜¯å¦å­˜åœ¨
    relations_file = os.path.join(csv_dir, 'relations.csv')
    if os.path.exists(relations_file):
        with open(relations_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for i, row in enumerate(reader, 1):
                from_id = row.get('from_id', '')
                to_id = row.get('to_id', '')
                
                if from_id and from_id not in all_node_ids:
                    issues.append(f"å…³ç³» {i}: èµ·å§‹èŠ‚ç‚¹ä¸å­˜åœ¨ ({from_id})")
                if to_id and to_id not in all_node_ids:
                    issues.append(f"å…³ç³» {i}: ç›®æ ‡èŠ‚ç‚¹ä¸å­˜åœ¨ ({to_id})")
                
                if len(issues) >= 20:  # åªæŠ¥å‘Šå‰20ä¸ªé—®é¢˜
                    break
    
    if issues:
        print(f"âŒ å‘ç° {len(issues)} ä¸ªç»“æ„é—®é¢˜:")
        for issue in issues[:20]:
            print(f"   - {issue}")
        if len(issues) > 20:
            print(f"   ... è¿˜æœ‰ {len(issues) - 20} ä¸ªé—®é¢˜")
    else:
        print("âœ… ç»“æ„éªŒè¯é€šè¿‡")
    print()
    
    return {
        'issues': issues,
        'total_issues': len(issues)
    }


def generate_statistics_report(csv_dir: str, output_file: str = None):
    """ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š"""
    print("\n" + "=" * 60)
    print("ğŸ“‹ ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š")
    print("=" * 60)
    
    node_counts = count_nodes(csv_dir)
    relation_stats = count_relations(csv_dir)
    paper_stats = analyze_paper_statistics(csv_dir)
    connectivity_stats = analyze_node_connectivity(csv_dir)
    structure_validation = validate_structure(csv_dir)
    
    report = {
        'node_counts': node_counts,
        'relation_stats': relation_stats,
        'paper_stats': paper_stats,
        'connectivity_stats': connectivity_stats,
        'structure_validation': structure_validation
    }
    
    if output_file:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2, default=str)
        print(f"\nâœ… æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
    
    return report


def main():
    """ä¸»å‡½æ•°"""
    script_dir = os.path.dirname(os.path.abspath(__file__))
    csv_dir = os.path.join(script_dir, 'csv')
    
    if not os.path.exists(csv_dir):
        print(f"âŒ CSV ç›®å½•ä¸å­˜åœ¨: {csv_dir}")
        print("   è¯·å…ˆè¿è¡Œ json_to_csv.py ç”Ÿæˆ CSV æ–‡ä»¶")
        return
    
    output_file = os.path.join(script_dir, 'statistics_report.json')
    generate_statistics_report(csv_dir, output_file)


if __name__ == '__main__':
    main()

