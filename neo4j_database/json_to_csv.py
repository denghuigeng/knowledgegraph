#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°† standard.json è½¬æ¢ä¸º Neo4j èŠ‚ç‚¹ CSV å’Œå…³ç³» CSV
"""

import json
import csv
import os
from collections import defaultdict
from typing import Dict, List, Set, Any
import hashlib


def normalize_string(s: str) -> str:
    """è§„èŒƒåŒ–å­—ç¬¦ä¸²ï¼Œç”¨äºç”Ÿæˆå”¯ä¸€ID"""
    if not s:
        return ""
    return s.strip()


def generate_node_id(node_type: str, name: str) -> str:
    """ç”ŸæˆèŠ‚ç‚¹å”¯ä¸€ID"""
    normalized_name = normalize_string(name)
    # ä½¿ç”¨ç±»å‹å’Œåç§°ç”Ÿæˆå”¯ä¸€ID
    unique_str = f"{node_type}:{normalized_name}"
    # ä½¿ç”¨å“ˆå¸Œç¡®ä¿IDå”¯ä¸€ä¸”å›ºå®šé•¿åº¦
    return hashlib.md5(unique_str.encode('utf-8')).hexdigest()[:16]


def extract_nodes_and_relations(data: List[Dict]) -> tuple:
    """ä» JSON æ•°æ®ä¸­æå–æ‰€æœ‰èŠ‚ç‚¹å’Œå…³ç³»"""
    nodes = {
        'Paper': [],
        'Task': [],
        'ImagingModality': [],
        'AnatomicalStructure': [],
        'Method': [],
        'Dataset': [],
        'Metric': [],
        'Innovation': []
    }
    
    relations = []
    node_set = defaultdict(set)  # ç”¨äºå»é‡
    node_name_to_id = {}  # èŠ‚ç‚¹åç§°åˆ°IDçš„æ˜ å°„
    
    for paper in data:
        paper_id = paper.get('paper_id', '')
        
        # 1. åˆ›å»º Paper èŠ‚ç‚¹
        if paper_id:
            paper_node = {
                'id': paper_id,
                'paper_id': paper_id,
                'title': paper.get('title', ''),
                'doi': paper.get('doi', ''),
                'year': paper.get('year', ''),
                'category': paper.get('category', ''),
                'authors': '|'.join(paper.get('authors', [])),
                'embedding': ''  # ç¨åå¡«å……
            }
            if paper_id not in node_set['Paper']:
                nodes['Paper'].append(paper_node)
                node_set['Paper'].add(paper_id)
        
        # 2. æå– Task èŠ‚ç‚¹
        for task in paper.get('tasks', []):
            task_normalized = normalize_string(task)
            if task_normalized and task_normalized not in node_set['Task']:
                task_id = generate_node_id('Task', task_normalized)
                nodes['Task'].append({
                    'id': task_id,
                    'name': task_normalized,
                    'type': 'Task',
                    'embedding': ''
                })
                node_set['Task'].add(task_normalized)
                node_name_to_id[f'Task:{task_normalized}'] = task_id
        
        # 3. æå– ImagingModality èŠ‚ç‚¹
        for modality in paper.get('imaging_modalities', []):
            modality_normalized = normalize_string(modality)
            if modality_normalized and modality_normalized not in node_set['ImagingModality']:
                modality_id = generate_node_id('ImagingModality', modality_normalized)
                nodes['ImagingModality'].append({
                    'id': modality_id,
                    'name': modality_normalized,
                    'type': 'ImagingModality',
                    'embedding': ''
                })
                node_set['ImagingModality'].add(modality_normalized)
                node_name_to_id[f'ImagingModality:{modality_normalized}'] = modality_id
        
        # 4. æå– AnatomicalStructure èŠ‚ç‚¹
        for structure in paper.get('anatomical_structures', []):
            structure_normalized = normalize_string(structure)
            if structure_normalized and structure_normalized not in node_set['AnatomicalStructure']:
                structure_id = generate_node_id('AnatomicalStructure', structure_normalized)
                nodes['AnatomicalStructure'].append({
                    'id': structure_id,
                    'name': structure_normalized,
                    'type': 'AnatomicalStructure',
                    'embedding': ''
                })
                node_set['AnatomicalStructure'].add(structure_normalized)
                node_name_to_id[f'AnatomicalStructure:{structure_normalized}'] = structure_id
        
        # 5. æå– Method èŠ‚ç‚¹
        for method in paper.get('methods', []):
            method_name = normalize_string(method.get('name', ''))
            if method_name and method_name not in node_set['Method']:
                method_id = generate_node_id('Method', method_name)
                nodes['Method'].append({
                    'id': method_id,
                    'name': method_name,
                    'method_type': method.get('type', ''),
                    'type': 'Method',
                    'embedding': ''
                })
                node_set['Method'].add(method_name)
                node_name_to_id[f'Method:{method_name}'] = method_id
        
        # 6. æå– Dataset èŠ‚ç‚¹
        for dataset in paper.get('datasets', []):
            dataset_normalized = normalize_string(dataset)
            if dataset_normalized and dataset_normalized not in node_set['Dataset']:
                dataset_id = generate_node_id('Dataset', dataset_normalized)
                nodes['Dataset'].append({
                    'id': dataset_id,
                    'name': dataset_normalized,
                    'type': 'Dataset',
                    'embedding': ''
                })
                node_set['Dataset'].add(dataset_normalized)
                node_name_to_id[f'Dataset:{dataset_normalized}'] = dataset_id
        
        # 7. æå– Metric èŠ‚ç‚¹
        for metric in paper.get('metrics', []):
            metric_name = normalize_string(metric.get('name', ''))
            if metric_name:
                metric_key = f"{metric_name}"  # ä½¿ç”¨åç§°ä½œä¸ºå”¯ä¸€é”®
                if metric_key not in node_set['Metric']:
                    metric_id = generate_node_id('Metric', metric_name)
                    nodes['Metric'].append({
                        'id': metric_id,
                        'name': metric_name,
                        'type': 'Metric',
                        'embedding': ''
                    })
                    node_set['Metric'].add(metric_key)
                    node_name_to_id[f'Metric:{metric_name}'] = metric_id
        
        # 8. æå– Innovation èŠ‚ç‚¹
        for innovation in paper.get('innovations', []):
            innovation_desc = normalize_string(innovation.get('description', ''))
            if innovation_desc:
                innovation_key = innovation_desc  # ä½¿ç”¨æè¿°ä½œä¸ºå”¯ä¸€é”®
                if innovation_key not in node_set['Innovation']:
                    innovation_id = generate_node_id('Innovation', innovation_desc)
                    nodes['Innovation'].append({
                        'id': innovation_id,
                        'description': innovation_desc,
                        'innovation_type': innovation.get('type', ''),
                        'type': 'Innovation',
                        'embedding': ''
                    })
                    node_set['Innovation'].add(innovation_key)
                    node_name_to_id[f'Innovation:{innovation_desc}'] = innovation_id
        
        # 9. æå–å…³ç³»
        for relation in paper.get('relations', []):
            rel_type = relation.get('type', '')
            from_entity = relation.get('from', '')
            to_entity = relation.get('to', '')
            value = relation.get('value', '')
            note = relation.get('note', '')
            
            if not rel_type or not from_entity or not to_entity:
                continue
            
            # ç¡®å®š from å’Œ to çš„èŠ‚ç‚¹ID
            from_id = None
            to_id = None
            
            # å¤„ç† from èŠ‚ç‚¹
            if from_entity == paper_id:
                from_id = paper_id
            else:
                # å°è¯•åŒ¹é…å„ç§èŠ‚ç‚¹ç±»å‹
                from_normalized = normalize_string(from_entity)
                for node_type in ['Task', 'ImagingModality', 'AnatomicalStructure', 
                                 'Method', 'Dataset', 'Metric', 'Innovation']:
                    key = f'{node_type}:{from_normalized}'
                    if key in node_name_to_id:
                        from_id = node_name_to_id[key]
                        break
            
            # å¤„ç† to èŠ‚ç‚¹
            to_normalized = normalize_string(to_entity)
            for node_type in ['Task', 'ImagingModality', 'AnatomicalStructure', 
                             'Method', 'Dataset', 'Metric', 'Innovation']:
                key = f'{node_type}:{to_normalized}'
                if key in node_name_to_id:
                    to_id = node_name_to_id[key]
                    break
            
            if from_id and to_id:
                rel_row = {
                    'from_id': from_id,
                    'to_id': to_id,
                    'type': rel_type,
                    'value': value if value else '',
                    'note': note if note else ''
                }
                relations.append(rel_row)
    
    return nodes, relations


def write_nodes_csv(nodes: Dict[str, List[Dict]], output_dir: str):
    """å°†èŠ‚ç‚¹å†™å…¥ CSV æ–‡ä»¶"""
    for node_type, node_list in nodes.items():
        if not node_list:
            continue
        
        filename = os.path.join(output_dir, f'nodes_{node_type}.csv')
        fieldnames = list(node_list[0].keys())
        
        with open(filename, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(node_list)
        
        print(f"âœ“ å·²ç”ŸæˆèŠ‚ç‚¹æ–‡ä»¶: {filename} ({len(node_list)} ä¸ªèŠ‚ç‚¹)")


def write_relations_csv(relations: List[Dict], output_dir: str):
    """å°†å…³ç³»å†™å…¥ CSV æ–‡ä»¶"""
    if not relations:
        print("âš  æ²¡æœ‰å…³ç³»æ•°æ®")
        return
    
    filename = os.path.join(output_dir, 'relations.csv')
    fieldnames = ['from_id', 'to_id', 'type', 'value', 'note']
    
    with open(filename, 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(relations)
    
    print(f"âœ“ å·²ç”Ÿæˆå…³ç³»æ–‡ä»¶: {filename} ({len(relations)} æ¡å…³ç³»)")


def main():
    """ä¸»å‡½æ•°"""
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(script_dir)
    
    input_file = os.path.join(project_root, 'standard.json')
    output_dir = os.path.join(script_dir, 'csv')
    
    os.makedirs(output_dir, exist_ok=True)
    
    print(f"ğŸ“– è¯»å–æ–‡ä»¶: {input_file}")
    with open(input_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print(f"ğŸ“Š å¤„ç† {len(data)} ç¯‡è®ºæ–‡...")
    nodes, relations = extract_nodes_and_relations(data)
    
    print(f"\nğŸ“ ç”Ÿæˆ CSV æ–‡ä»¶...")
    write_nodes_csv(nodes, output_dir)
    write_relations_csv(relations, output_dir)
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_nodes = sum(len(v) for v in nodes.values())
    print(f"\nâœ… è½¬æ¢å®Œæˆ!")
    print(f"   æ€»èŠ‚ç‚¹æ•°: {total_nodes}")
    print(f"   æ€»å…³ç³»æ•°: {len(relations)}")
    print(f"   èŠ‚ç‚¹ç±»å‹åˆ†å¸ƒ:")
    for node_type, node_list in nodes.items():
        print(f"     - {node_type}: {len(node_list)}")


if __name__ == '__main__':
    main()

